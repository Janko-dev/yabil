#include <stdio.h>
#include <stdlib.h>
#include "../common/common.h"
#include "../common/object.h"
#include "compiler.h"
#include "lexer.h"

#ifdef DEBUG_PRINT_CODE
#include "../common/debug.h"
#endif //DEBUG_PRINT_CODE

Chunk* compiling_chunk;
Lexer lexer;
Parser parser;

static ParseRule* get_rule(TokenType type);
static void declaration();
static void var_declaration();
static void statement();
static void print_statement();
static void expression_statement();

static void expression();
static void parse_precedence(Precedence prec);

static size_t get_column(Token* token){
    size_t col;
    for (col = 0; token->start[token->length-col-1] != '\n' && 
                ((token->start + token->length - col-1) - lexer.source) >= 0; col++);
    return col;
}

static void error_at(Token* token, const char* message){
    if (parser.panic_mode) return;
    parser.panic_mode = true;
    fprintf(stderr, "[line %d:%d] Error", token->line, get_column(token));
    if (token->type == TOKEN_EOF){
        fprintf(stderr, " at end");
    } else if (token->type == TOKEN_ERROR) {
        // nothing
    } else {
        fprintf(stderr, " at '%.*s'", token->length, token->start);
    }
    fprintf(stderr, ": %s\n", message);
    parser.had_error = true;
}

static void error_at_current(const char* message){
    error_at(&parser.current, message);
}

static void error(const char* message){
    error_at(&parser.previous, message);
}

static void advance(){
    parser.previous = parser.current;
    for(;;){
        parser.current = scan_token(&lexer);
        if (parser.current.type != TOKEN_ERROR) break;
        error_at_current(parser.current.err_msg);
    }
}

static void consume(TokenType type, const char* message){
    if (parser.current.type == type){
        advance();
        return;
    }
    error_at_current(message);
}

static bool match(TokenType type){
    if (parser.current.type != type) return false;
    advance();
    return true;
}

static Chunk* current_chunk(){
    return compiling_chunk;
}

static void emit_byte(uint8_t byte){
    write_chunk(current_chunk(), byte, parser.previous.line);
}

static void emit_bytes(uint8_t byte1, uint8_t byte2){
    write_chunk(current_chunk(), byte1, parser.previous.line);
    write_chunk(current_chunk(), byte2, parser.previous.line);
}

// static size_t identifier_constant(Token* name){
//     return add_constant(current_chunk(), OBJ_VAL(copy_string(name->start, name->length)));
// }

static void end_compiler(){
    emit_byte(OP_RETURN);
#ifdef DEBUG_PRINT_CODE
    if (!parser.had_error){
        disassemble_chunk(current_chunk(), "Compilation step: generated byte-code");
    }
#endif //DEBUG_PRINT_CODE
}

static void synchronize(){
    parser.panic_mode = false;
    while (parser.current.type != TOKEN_EOF){
        if (parser.previous.type == TOKEN_SEMICOLON) return;
        switch(parser.current.type){
            case TOKEN_CLASS: case TOKEN_FUN:    case TOKEN_VAR:
            case TOKEN_FOR:   case TOKEN_IF:     case TOKEN_WHILE:
            case TOKEN_PRINT: case TOKEN_RETURN: 
                return;
            default:;
        }
        advance();
    }
}

static void parse_precedence(Precedence prec){
    advance();
    if (parser.previous.type == TOKEN_EOF) return;
    ParseFn prefix_rule = get_rule(parser.previous.type)->prefix;
    if (prefix_rule == NULL){
        error("Expected an expression");
        return;
    }
    bool can_assign = prec <= PREC_ASSIGNMENT;
    prefix_rule(can_assign);

    while(prec <= get_rule(parser.current.type)->precedence){
        advance();
        get_rule(parser.previous.type)->infix(can_assign);
    }

    if (can_assign && match(TOKEN_EQUAL)){
        error("Invalid assignment target");
    }
}

static void declaration(){
    if (match(TOKEN_VAR)){
        var_declaration();
    } else {
        statement();
    }
    if (parser.panic_mode) synchronize();
}

static void var_declaration(){
    consume(TOKEN_IDENTIFIER, "expected a variable name identifier");
    Value value = OBJ_VAL(copy_string(parser.previous.start, parser.previous.length));
    // size_t global = identifier_constant(&parser.previous);
    if (match(TOKEN_EQUAL)){
        expression();
    } else {
        emit_byte(OP_NIL);
    }
    consume(TOKEN_SEMICOLON, "Expected ';' after variable declaration");
    
    if (current_chunk()->constants.count + 1 > UINT8_MAX){
        emit_byte(OP_DEFINE_GLOBAL_LONG);
        write_constant(current_chunk(), value, parser.previous.line);
    } else {
        emit_bytes(OP_DEFINE_GLOBAL, add_constant(current_chunk(), value));
    }
}

static void statement(){
    if (match(TOKEN_PRINT)){
        print_statement();
    } else {
        expression_statement();
    }
}

static void print_statement(){
    expression();
    consume(TOKEN_SEMICOLON, "Expected ';' after value");
    emit_byte(OP_PRINT);
}

static void expression_statement(){
    expression();
    consume(TOKEN_SEMICOLON, "Expected ';' after value");
    emit_byte(OP_POP);
}

static void expression(){
    parse_precedence(PREC_ASSIGNMENT);
}

static void number(bool can_assign){
    UNUSED(can_assign);
    double value = strtod(parser.previous.start, NULL);
    if (current_chunk()->constants.count + 1 > UINT8_MAX){
        emit_byte(OP_CONSTANT_LONG);
        write_constant(current_chunk(), NUM_VAL(value), parser.previous.line);
    } else {
        emit_bytes(OP_CONSTANT, add_constant(current_chunk(), NUM_VAL(value)));
    }
}

static void literal(bool can_assign){
    UNUSED(can_assign);
    switch(parser.previous.type){
        case TOKEN_NIL:   emit_byte(OP_NIL); break;
        case TOKEN_TRUE:  emit_byte(OP_TRUE); break;
        case TOKEN_FALSE: emit_byte(OP_FALSE); break;
        default: return;
    }
}

static void string(bool can_assign){
    UNUSED(can_assign);
    Value value = OBJ_VAL(copy_string(parser.previous.start+1, parser.previous.length-2));
    if (current_chunk()->constants.count + 1 > UINT8_MAX){
        emit_byte(OP_CONSTANT_LONG);
        write_constant(current_chunk(), value, parser.previous.line);
    } else {
        emit_bytes(OP_CONSTANT, add_constant(current_chunk(), value));
    }
}

static void variable(bool can_assign){
    Value value = OBJ_VAL(copy_string(parser.previous.start, parser.previous.length));
    
    if (can_assign && match(TOKEN_EQUAL)){
        expression();
        if (current_chunk()->constants.count + 1 > UINT8_MAX){
            emit_byte(OP_SET_GLOBAL_LONG);
            write_constant(current_chunk(), value, parser.previous.line);
        } else {
            emit_bytes(OP_SET_GLOBAL, add_constant(current_chunk(), value));
        }
    } else {
        if (current_chunk()->constants.count + 1 > UINT8_MAX){
            emit_byte(OP_GET_GLOBAL_LONG);
            write_constant(current_chunk(), value, parser.previous.line);
        } else {
            emit_bytes(OP_GET_GLOBAL, add_constant(current_chunk(), value));
        }
    }

}

static void grouping(bool can_assign){
    UNUSED(can_assign);
    expression();
    consume(TOKEN_RIGHT_PAREN, "Expected ')' after expression");
}

static void array(bool can_assign){
    UNUSED(can_assign);
    size_t count = 0;
    if (!match(TOKEN_RIGHT_BRACKET)){
        expression();
        count++;
        while(!match(TOKEN_RIGHT_BRACKET)){
            consume(TOKEN_COMMA, "Expected ',' in list");
            if (match(TOKEN_RIGHT_BRACKET)) break;
            expression();
            count++;
        }
    }

    if (count > UINT8_MAX){
        emit_bytes(OP_ARRAY_LONG, count);
        emit_bytes(count >> 8, count >> 16);
    } else {
        emit_bytes(OP_ARRAY, count);
    }
}

static void unary(bool can_assign){
    UNUSED(can_assign);
    TokenType operator = parser.previous.type;
    parse_precedence(PREC_UNARY);
    switch(operator){
        case TOKEN_MINUS: emit_byte(OP_NEGATE); break;
        case TOKEN_BANG: emit_byte(OP_NOT); break;
        default: return;
    }
}

static void binary(bool can_assign){
    UNUSED(can_assign);
    TokenType operator = parser.previous.type;
    ParseRule* rule = get_rule(operator);
    parse_precedence((Precedence)(rule->precedence+1));
    switch(operator){
        case TOKEN_PLUS:           emit_byte(OP_ADD); break;
        case TOKEN_MINUS:          emit_byte(OP_SUB); break;
        case TOKEN_STAR:           emit_byte(OP_MUL); break;
        case TOKEN_SLASH:          emit_byte(OP_DIV); break;
        // equality and comparison
        case TOKEN_BANG_EQUAL:     emit_byte(OP_NOT_EQUAL); break;
        case TOKEN_EQUAL_EQUAL:    emit_byte(OP_EQUAL); break;
        case TOKEN_LESS:           emit_byte(OP_LESS); break;
        case TOKEN_LESS_EQUAL:     emit_byte(OP_LESS_EQUAL); break;
        case TOKEN_GREATER:        emit_byte(OP_GREATER); break;
        case TOKEN_GREATER_EQUAL:  emit_byte(OP_GREATER_EQUAL); break;
        default: return;
    }
}

// TODO: implement ternary
static void ternary(bool can_assign){
    UNUSED(can_assign);
    // TokenType qmark = parser.previous.type;
    expression();
    consume(TOKEN_COLON, "expected ':' in ternary expression");
    expression();
}


ParseRule rules[] = { //      prefix     infix     precedence
    [TOKEN_LEFT_PAREN]     = {grouping,  NULL,     PREC_NONE},    
    [TOKEN_RIGHT_PAREN]    = {NULL,      NULL,     PREC_NONE},    
    [TOKEN_LEFT_BRACE]     = {NULL,      NULL,     PREC_NONE}, 
    [TOKEN_RIGHT_BRACE]    = {NULL,      NULL,     PREC_NONE},
    [TOKEN_LEFT_BRACKET]   = {array,     NULL,     PREC_NONE}, 
    [TOKEN_RIGHT_BRACKET]  = {NULL,      NULL,     PREC_NONE},
    [TOKEN_COMMA]          = {NULL,      NULL,     PREC_NONE}, 
    [TOKEN_DOT]            = {NULL,      NULL,     PREC_NONE}, 
    [TOKEN_MINUS]          = {unary,     binary,   PREC_TERM}, 
    [TOKEN_PLUS]           = {NULL,      binary,   PREC_TERM},
    [TOKEN_SEMICOLON]      = {NULL,      NULL,     PREC_NONE}, 
    [TOKEN_SLASH]          = {NULL,      binary,   PREC_FACTOR}, 
    [TOKEN_STAR]           = {NULL,      binary,   PREC_FACTOR},
    [TOKEN_QMARK]          = {NULL,      ternary,  PREC_TERNARY}, 
    [TOKEN_COLON]          = {NULL,      NULL,     PREC_NONE},
    [TOKEN_BANG]           = {unary,     NULL,     PREC_NONE}, 
    [TOKEN_BANG_EQUAL]     = {NULL,      binary,   PREC_EQUALITY}, 
    [TOKEN_EQUAL]          = {NULL,      NULL,     PREC_NONE}, 
    [TOKEN_EQUAL_EQUAL]    = {NULL,      binary,   PREC_EQUALITY},
    [TOKEN_GREATER]        = {NULL,      binary,   PREC_COMPARISON}, 
    [TOKEN_GREATER_EQUAL]  = {NULL,      binary,   PREC_COMPARISON}, 
    [TOKEN_LESS]           = {NULL,      binary,   PREC_COMPARISON}, 
    [TOKEN_LESS_EQUAL]     = {NULL,      binary,   PREC_COMPARISON},
    [TOKEN_IDENTIFIER]     = {variable,  NULL,     PREC_NONE}, 
    [TOKEN_STRING]         = {string,    NULL,     PREC_NONE},
    [TOKEN_NUMBER]         = {number,    NULL,     PREC_NONE},
    [TOKEN_AND]            = {NULL,      NULL,     PREC_NONE}, 
    [TOKEN_OR]             = {NULL,      NULL,     PREC_NONE}, 
    [TOKEN_PRINT]          = {NULL,      NULL,     PREC_NONE}, 
    [TOKEN_IF]             = {NULL,      NULL,     PREC_NONE}, 
    [TOKEN_ELSE]           = {NULL,      NULL,     PREC_NONE}, 
    [TOKEN_TRUE]           = {literal,   NULL,     PREC_NONE}, 
    [TOKEN_FALSE]          = {literal,   NULL,     PREC_NONE}, 
    [TOKEN_NIL]            = {literal,   NULL,     PREC_NONE},
    [TOKEN_FOR]            = {NULL,      NULL,     PREC_NONE}, 
    [TOKEN_WHILE]          = {NULL,      NULL,     PREC_NONE}, 
    [TOKEN_FUN]            = {NULL,      NULL,     PREC_NONE}, 
    [TOKEN_RETURN]         = {NULL,      NULL,     PREC_NONE}, 
    [TOKEN_CLASS]          = {NULL,      NULL,     PREC_NONE}, 
    [TOKEN_SUPER]          = {NULL,      NULL,     PREC_NONE}, 
    [TOKEN_THIS]           = {NULL,      NULL,     PREC_NONE}, 
    [TOKEN_VAR]            = {NULL,      NULL,     PREC_NONE},
    [TOKEN_ERROR]          = {NULL,      NULL,     PREC_NONE}, 
    [TOKEN_EOF]            = {NULL,      NULL,     PREC_NONE}, 
};

static ParseRule* get_rule(TokenType type){
    return &rules[type];
}

bool compile(const char* source, Chunk* chunk){
    compiling_chunk = chunk;

    init_lexer(&lexer, source);
    parser.had_error = false;
    parser.panic_mode = false;

    advance();
    while(!match(TOKEN_EOF)){
        declaration();
    }
    end_compiler();
    return !parser.had_error;
}

void print_tokens(Lexer* lexer){
    size_t line = -1;
    for (;;){
        Token token = scan_token(lexer);
        if(token.line != line){
            printf("%4d ", token.line);
            line = token.line;
        } else {
            printf("   | ");
        }
        printf("%2d '%.*s'\n", token.type, token.length, token.start);
        if (token.type == TOKEN_EOF) break;
    }
}